version: '3.7'

services:

  # The 'setup' service runs a one-off script which initializes the
  # 'logstash_internal' and 'kibana_system' users inside Elasticsearch with the
  # values of the passwords defined in the '.env' file.
  #
  # This task is only performed during the *initial* startup of the stack. On all
  # subsequent runs, the service simply returns immediately, without performing
  # any modification to existing users.
  # setup:
  #   build:
  #     context: setup/
  #     args:
  #       ELASTIC_VERSION: ${ELASTIC_VERSION}
  #   init: true
  #   volumes:
  #     - setup:/state:Z
  #   environment:
  #     ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
  #     LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
  #     KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
  #   networks:
  #     - elk

  elasticsearch:
    build:
      context: elasticsearch/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,z
      - elasticsearch:/usr/share/elasticsearch/data:z
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: -Xmx256m -Xms256m
      # Bootstrap password.
      # Used to initialize the keystore during the initial startup of
      # Elasticsearch. Ignored on subsequent runs.
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    # networks:
    #   - elk

  logstash:
    build:
      context: logstash/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro,Z
    ports:
      - "5044:5044"
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: -Xmx256m -Xms256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    # networks:
    #   - elk
    depends_on:
      - elasticsearch
      - kafka

  kibana:
    build:
      context: kibana/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
    ports:
      - "5601:5601"
    environment:
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    # networks:
    #   - elk
    depends_on:
      - elasticsearch
  zookeeper:
    image: wurstmeister/zookeeper
    hostname: zookeeper
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_DATA_DIR: /zookeeper/data
    container_name: zookeeper
    ports:
      - "2181:2181"
    volumes:
      - ./zookeeper/data/1:/zookeeper/data
  
  kafka:
    image: wurstmeister/kafka:2.12-2.5.0
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      #내부에서 접근
      KAFKA_LISTENERS: PLAINTEXT://kafka:9092
      #외부에서 접근
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092    
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_LOG_DIRS: /tmp/kafka-logs
    volumes:
      - ./kafka/logs/1:/tmp/kafka-logs
    depends_on:
      - zookeeper
  akhq:
    image: tchiotludo/akhq:latest
    hostname: akhq
    depends_on:
      - kafka
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            kafka:
              properties:
                bootstrap.servers: kafka:9092
    ports:
      - 8080:8080

# networks:
#   elk:
#     driver: bridge


volumes:
  # setup:
  elasticsearch:
